{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUNY MSDA DATA 620\n",
    "### Homework 10-11: Document classification\n",
    "By Dmitriy Vecheruk\n",
    "\n",
    "### Assignment\n",
    "*It can be useful to be able to classify new \"test\" documents using already classified \"training\" documents.  A common example is using a corpus of labeled spam and ham (non-spam) e-mails to predict whether or not a new document is spam.  \n",
    "For this project, you can either use the above dataset to predict the class of new documents (either withheld from the training dataset or from another source such as your own spam folder).*\n",
    "\n",
    "*For more adventurous students, you are welcome (encouraged!) to come up a different set of documents (including scraped web pages!?) that have already been classified (e.g. tagged), then analyze these documents to predict how new documents should be classified.*\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Solution\n",
    "\n",
    "#### Dataset\n",
    "For this assignment, I will use the famous Reuters news dataset that comes with the NLTK package. According to the documentaion, \"The Reuters Corpus contains 10,788 news documents totaling 1.3 million words. The documents have been classified into 90 topics, and grouped into two sets, called 'training' and 'test'. [1]\n",
    "  \n",
    "#### Approach\n",
    "The analysis is conducted as follows and uses the functionality of `nltk` and `sklearn` libraries and the general approach to training an LDA classifier outlined in [2,3].\n",
    "  \n",
    "1) Read and prepare the training documents  \n",
    "2) Train an LDA model on the training dataset  \n",
    "3) Apply the model on the test data and evaluate its performance in terms of correct topic recognition  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.corpus import reuters\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk import FreqDist\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test/14826', 'test/14828', 'test/14829', 'test/14832', 'test/14833']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters.fileids()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to inspect which are the 90 topics listed in the documentation and how often they appear in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acq alum barley bop carcass castor-oil cocoa coconut coconut-oil coffee copper copra-cake corn cotton cotton-oil cpi cpu crude dfl dlr dmk earn fuel gas gnp gold grain groundnut groundnut-oil heat hog housing income instal-debt interest ipi iron-steel jet jobs l-cattle lead lei lin-oil livestock lumber meal-feed money-fx money-supply naphtha nat-gas nickel nkr nzdlr oat oilseed orange palladium palm-oil palmkernel pet-chem platinum potato propane rand rape-oil rapeseed reserves retail rice rubber rye ship silver sorghum soy-meal soy-oil soybean strategic-metal sugar sun-meal sun-oil sunseed tea tin trade veg-oil wheat wpi yen zinc\n"
     ]
    }
   ],
   "source": [
    "for item in reuters.categories(): print item,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'earn', 3923),\n",
       " (u'acq', 2292),\n",
       " (u'crude', 374),\n",
       " (u'trade', 326),\n",
       " (u'money-fx', 309),\n",
       " (u'interest', 272),\n",
       " (u'interest money-fx', 167),\n",
       " (u'money-supply', 151),\n",
       " (u'grain wheat', 150),\n",
       " (u'ship', 144)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the frequency of the topics\n",
    "\n",
    "cat_freq = []\n",
    "for elem in reuters.fileids():\n",
    "    cat_freq.append(reuters.categories(elem))\n",
    "\n",
    "topics = [' '.join(item) for item in cat_freq]\n",
    "topics_freq = FreqDist(topics)\n",
    "\n",
    "# Order topics by frequency\n",
    "topics_freq.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that by far the most common topics are the inscrutiable terms \"earn\" and \"acq\". \n",
    "  \n",
    "The documents tagged as \"earn\" are related to the earnings of corporate shareholders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMATIL PROPOSES TWO - FOR - FIVE BONUS SHARE ISSUE Amatil Ltd & lt ; AMAA . S > said it proposes to make a two - for - five bonus issue out of its revaluation reserve to shareholders registered May 26 . Shareholders will be asked to approve the issue and an increase in authorised capital to 175 mln shares from 125 mln at a general meeting on May 1 , it said in a statement . The new shares will rank for dividends declared after October 31 . Amatil , in which B . A . T .\n"
     ]
    }
   ],
   "source": [
    "for item in reuters.words(categories='earn')[:100] : print item, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "while the profit from U . K . Operations rose 30 . 7 pct to 24 . 7 mln , and Europe , 42 . 9 pct to 11 . 0 mln . CITIBANK NORWAY UNIT LOSES SIX MLN CROWNS IN 1986 Citibank A / S & lt ; CCI . N >, the Norwegian subsidiary of the U . S .- based bank , said it made a net loss of just over six mln crowns in 1986 -- although foreign bankers said they expect it to show 1987 profits after two lean years . Citibank ' s Oslo\n"
     ]
    }
   ],
   "source": [
    "for item in reuters.words(categories='earn')[500:600] : print item, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The documents tagged as \"acq\" are related to corporate mergers and acquisitions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMITOMO BANK AIMS AT QUICK RECOVERY FROM MERGER Sumitomo Bank Ltd & lt ; SUMI . T > is certain to lose its status as Japan ' s most profitable bank as a result of its merger with the Heiwa Sogo Bank , financial analysts said . Osaka - based Sumitomo , with desposits of around 23 . 9 trillion yen , merged with Heiwa Sogo , a small , struggling bank with an estimated 1 . 29 billion dlrs in unrecoverable loans , in October . But despite the link - up , Sumitomo President Koh Komatsu told Reuters\n"
     ]
    }
   ],
   "source": [
    "for item in reuters.words(categories='acq')[:100] : print item, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", to be repaid by the mining company in gold . Atlas said the two sides were also discussing equity infusion into Atlas and the creation of a development fund for further exploration and development of the company ' s gold properties in the central province of Masbate . Wilson Banks , general manager of & lt ; Bond Corp International Ltd > in Hong Kong , told Reuters the Atlas statement on the negotiations was \" reasonably accurate .\" Banks said Bond Corp was seriously considering several investments in the Philippines but did not give details . In its\n"
     ]
    }
   ],
   "source": [
    "for item in reuters.words(categories='acq')[1000:1100] : print item, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further modeling, these two top topics will be used exclusively, meaning that the topic model should be able to infer if a document relates to \"earn\", \"acq\", or both topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create filtered training and test datasets\n",
    "reuters_filt_ids = reuters.fileids(categories=[\"earn\",\"acq\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the topics of the text are \"crude\"(oil) and \"ship\". But in order to model the topics, we need to convert each of the training texts into a bag of stemmed words, exclude punctuation and numbers, and exclude the \"stopwords\" occurring across all topics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clean the input and train the LDA classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_fileids = [item for item in reuters_filt_ids if 'train' in item]\n",
    "test_fileids = [item for item in reuters_filt_ids if 'test' in item]\n",
    "\n",
    "train_docs = [reuters.words(item) for item in train_fileids]\n",
    "train_docs = [' '.join(item) for item in train_docs]\n",
    "\n",
    "test_docs = [reuters.words(item) for item in test_fileids]\n",
    "test_docs = [' '.join(item) for item in test_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training documents: 4511, test documents: 1803\n"
     ]
    }
   ],
   "source": [
    "print \"Training documents: {}, test documents: {}\".format(len(train_fileids), len(test_fileids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we build a vocabulary of the thousand top most frequent terms appearing in all of the training documents minus the English language stop words. A vocabulary of a thousand terms should be sufficient to have enough variation in order to describe each of the two topics using different terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "\n",
    "# words occurring in only two documents or in at least 90% of the documents are removed.\n",
    "\n",
    "tf_vectorizer = CountVectorizer(max_df=0.9, min_df=5, max_features=vocab_size, \n",
    "                                analyzer = \"word\", token_pattern = r'\\b[a-z]\\w+\\b', \n",
    "                                stop_words='english', strip_accents=\"unicode\")\n",
    "\n",
    "tf = tf_vectorizer.fit_transform(train_docs)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply the Latent Dirichlet Allocation model to find the words most characteristic of each of the 90 topics from the vocabulary we have built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run LDA\n",
    "random_seed = 123\n",
    "no_topics = 2\n",
    "\n",
    "lda = LatentDirichletAllocation(n_topics=no_topics, max_iter=5, \n",
    "                                learning_method='online', \n",
    "                                learning_offset=50.,random_state=random_seed).fit(tf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "vs mln cts net loss dlrs shr year profit lt qtr revs billion note sales oper quarter share avg shrs\n",
      "Topic #1:\n",
      "said lt company dlrs pct shares mln corp share stock group offer april bank record dividend new common march stake\n"
     ]
    }
   ],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    \"\"\"\n",
    "    # Author: Olivier Grisel <olivier.grisel@ensta.org>\n",
    "    #         Lars Buitinck\n",
    "    #         Chyi-Kwei Yau <chyikwei.yau@gmail.com>\n",
    "    # License: BSD 3 clause\n",
    "    Source: http://scikit-learn.org/0.18/auto_examples/applications/topics_extraction_with_nmf_lda.html\n",
    "    \"\"\"\n",
    "    \n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "        \n",
    "no_top_words = 10\n",
    "print_top_words(lda, tf_feature_names, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inspection of the topic top words shows that \"Topic #0\" listing the terms \"profit, loss, billion\" corresponds to the input topic \"earn\", and \"Topic #1\" (terms like \"said\", \"company\", \"offer\", \"common\") corresponds to \"acq\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test and tune the topic model\n",
    "\n",
    "Now we'll use the trained LDA classifier to evaluate the documents in the test set and get the topic probability per document using the normalization approach described in [6].  \n",
    "After this step, the accuracy of the classification can be measured vs. the original topic labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.0029285 ,  0.9970715 ],\n",
       "        [ 0.10111091,  0.89888909],\n",
       "        [ 0.01629684,  0.98370316],\n",
       "        ..., \n",
       "        [ 0.91094571,  0.08905429],\n",
       "        [ 0.04657501,  0.95342499],\n",
       "        [ 0.00813371,  0.99186629]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict topics for test data\n",
    "# unnormalized doc-topic distribution\n",
    "tf_test = tf_vectorizer.transform(test_docs)\n",
    "doc_topic_dist_unnormalized = np.matrix(lda.transform(tf_test))\n",
    "\n",
    "# normalize the distribution \n",
    "doc_topic_dist = doc_topic_dist_unnormalized / doc_topic_dist_unnormalized.sum(axis=1)\n",
    "\n",
    "doc_topic_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the examples above, the assignment to the topic#0 (first column) or topic#1 (second column) is fairly exclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the most probable topic per test document and join to the document id\n",
    "topic_guess = [item[0] for item in np.array(doc_topic_dist.argmax(axis=1))]\n",
    "\n",
    "topic_guess_label = []\n",
    "for item in topic_guess:\n",
    "    if item == 1:\n",
    "        topic_guess_label.append(\"acq\")\n",
    "    else:\n",
    "        topic_guess_label.append(\"earn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_true = [reuters.categories(item) for item in test_fileids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_true_label = []\n",
    "\n",
    "for item in test_true:\n",
    "    if \"acq\" in item:\n",
    "        test_true_label.append(\"acq\")\n",
    "    elif \"earn\" in item:\n",
    "        test_true_label.append(\"earn\")\n",
    "\n",
    "#print zip(test_true[:15], test_true_label[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>acq</th>\n",
       "      <th>earn</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acq</th>\n",
       "      <td>716</td>\n",
       "      <td>3</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earn</th>\n",
       "      <td>155</td>\n",
       "      <td>929</td>\n",
       "      <td>1084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>871</td>\n",
       "      <td>932</td>\n",
       "      <td>1803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  acq  earn   All\n",
       "Actual                    \n",
       "acq        716     3   719\n",
       "earn       155   929  1084\n",
       "All        871   932  1803"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the assignments\n",
    "# Source: https://stackoverflow.com/a/29877565/8066374\n",
    "\n",
    "import pandas as pd\n",
    "y_actu = pd.Series(test_true_label, name='Actual')\n",
    "y_pred = pd.Series(topic_guess_label, name='Predicted')\n",
    "df_confusion = pd.crosstab(y_actu, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix shows the following classification performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic classification accuracy for the two topics: 91.2%\n"
     ]
    }
   ],
   "source": [
    "accuracy = (716.0 + 929)/1803\n",
    "print \"Topic classification accuracy for the two topics: {}%\".format(round(accuracy*100,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see that the LDA classifier tends to assign documents labeled as \"earn\" to the \"acq\" topic.\n",
    "If we had multiple dev_test sets, we could tune the sensitivity of the classifier by adjusting the probability threshold for the \"acq\" topic so as to reduce the faulty class assignments.\n",
    "  \n",
    "The example on the test set below shows how this could possibly work:  \n",
    "1) Calculate the mean probabilities for \"acq\" in the error cases and set it as a threshold probability for the class assignment  \n",
    "2) Re-evaluate the data using the threshold value from (1) instead of a simple argmax class probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    155.000000\n",
       "mean       0.723908\n",
       "std        0.153761\n",
       "min        0.504667\n",
       "25%        0.599823\n",
       "50%        0.671191\n",
       "75%        0.851892\n",
       "max        0.994473\n",
       "Name: 1_acq, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the distribution of class probabilites for the faulty assignments\n",
    "\n",
    "import numpy as np\n",
    "df = pd.concat([y_actu,y_pred,pd.DataFrame(doc_topic_dist,columns=[\"0_earn\",\"1_acq\"])],axis=1)\n",
    "errors = df[df.Actual != df.Predicted]\n",
    "errors[errors.Predicted == \"acq\"][\"1_acq\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>0_earn</th>\n",
       "      <th>1_acq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acq</td>\n",
       "      <td>acq</td>\n",
       "      <td>0.002928</td>\n",
       "      <td>0.997072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acq</td>\n",
       "      <td>acq</td>\n",
       "      <td>0.101111</td>\n",
       "      <td>0.898889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>earn</td>\n",
       "      <td>acq</td>\n",
       "      <td>0.016297</td>\n",
       "      <td>0.983703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>earn</td>\n",
       "      <td>earn</td>\n",
       "      <td>0.989712</td>\n",
       "      <td>0.010288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acq</td>\n",
       "      <td>acq</td>\n",
       "      <td>0.023205</td>\n",
       "      <td>0.976795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Actual Predicted    0_earn     1_acq\n",
       "0    acq       acq  0.002928  0.997072\n",
       "1    acq       acq  0.101111  0.898889\n",
       "2   earn       acq  0.016297  0.983703\n",
       "3   earn      earn  0.989712  0.010288\n",
       "4    acq       acq  0.023205  0.976795"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>New_Predicted</th>\n",
       "      <th>acq</th>\n",
       "      <th>earn</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acq</th>\n",
       "      <td>713</td>\n",
       "      <td>6</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earn</th>\n",
       "      <td>78</td>\n",
       "      <td>1006</td>\n",
       "      <td>1084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>791</td>\n",
       "      <td>1012</td>\n",
       "      <td>1803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "New_Predicted  acq  earn   All\n",
       "Actual                        \n",
       "acq            713     6   719\n",
       "earn            78  1006  1084\n",
       "All            791  1012  1803"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-evaluate class assignment using the mean probability in the error cases as a new threshold for \"acq\"\n",
    "df[\"new_Pred\"] = \"earn\"\n",
    "df.loc[df[\"1_acq\"] >= 0.671, \"new_Pred\"] = \"acq\"\n",
    "\n",
    "df_confusion_new = pd.crosstab(df[\"Actual\"],df[\"new_Pred\"], rownames=['Actual'], \n",
    "                               colnames=['New_Predicted'], margins=True)\n",
    "df_confusion_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic classification accuracy for the two topics after tuning: 95.5%\n"
     ]
    }
   ],
   "source": [
    "accuracy_new = (703.0 + 1018)/1803\n",
    "print \"Topic classification accuracy for the two topics after tuning: {}%\".format(round(accuracy_new*100,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a higher overall accuracy as a result (but we cannot test if this model is now overfitting the data as we've run out of test sets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "  \n",
    "### Reference\n",
    "1) http://www.nltk.org/book/ch02.html  \n",
    "2) https://medium.com/@aneesha/topic-modeling-with-scikit-learn-e80d33668730  \n",
    "3) http://scikit-learn.org/0.18/auto_examples/applications/topics_extraction_with_nmf_lda.html  \n",
    "4) http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html  \n",
    "5) http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html  \n",
    "6) https://stackoverflow.com/questions/40597075/python-sklearn-latent-dirichlet-allocation-transform-v-fittransform  \n",
    "7) https://stackoverflow.com/a/29877565/8066374 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
