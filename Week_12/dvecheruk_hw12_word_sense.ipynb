{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUNY MSDA DATA 620\n",
    "\n",
    "### Homework 12: Word sense disambiguation\n",
    "By Dmitriy Vecheruk  \n",
    "\n",
    "### Assignment  \n",
    "*The Senseval 2 Corpus contains data intended to train word-sense disambiguation classifiers. It contains data for four words: hard, interest, line, and serve. Choose one of these four words, and load the corresponding data. Using this dataset, build a classifier that predicts the correct sense tag for a given instance.* \n",
    "\n",
    "----\n",
    "### Solution\n",
    "\n",
    "From the four words available in the corpus, I have chosen the word **\"hard\"**. In order to build a word sense classifier, the following steps were taken:  \n",
    "  \n",
    "1) Inspect the dataset and clean if necessary, calculate the classifier accuracy baseline   \n",
    "2) Split the data into training and holdout (test) set  \n",
    "3) Extract the word context and part of speech features  \n",
    "4) Build a Naive Bayes classifier and test it on the dev-test set  \n",
    "5) Test the classifier on the holdout set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load, inspect and clean the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "import string\n",
    "from nltk.corpus import senseval, stopwords\n",
    "from nltk.classify import accuracy, NaiveBayesClassifier, apply_features\n",
    "from random import seed,shuffle\n",
    "\n",
    "# nltk.download() # use NLTK Corpus downloader to get the senseval and stopwords corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "instances = senseval.instances('hard.pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4333"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, there are 4333 instances in the dataset, an individual instance represents a sentence with POS tags and an indicator of the position of the word \"hard\", as well as a label for the word sense used in the sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SensevalInstance(word=u'hard-a', position=33, context=[('producers', 'NNS'), ('of', 'IN'), ('action', 'NN'), ('shows', 'VBZ'), (',', ','), ('like', 'IN'), ('cannell', 'NNP'), (',', ','), ('are', 'VBP'), ('willing', 'JJ'), ('to', 'TO'), ('make', 'VB'), ('them', 'PRP'), ('at', 'IN'), ('a', 'DT'), ('bargain', 'NN'), ('price', 'NN'), ('to', 'TO'), ('help', 'VB'), ('cbs', 'NNP'), ('open', 'JJ'), ('up', 'IN'), ('a', 'DT'), ('new', 'JJ'), ('market', 'NN'), ('for', 'IN'), ('one-hour', 'JJ'), ('action', 'NN'), ('shows', 'VBZ'), (',', ','), ('which', 'WDT'), ('have', 'VBP'), ('become', 'VBN'), ('hard', 'JJ'), ('to', 'TO'), ('sell', 'VB'), ('in', 'IN'), ('the', 'DT'), ('rerun', 'NN'), ('market', 'NN'), ('.', '.')], senses=('HARD1',))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get senses per instance\n",
    "senses = [item.senses for item in instances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('HARD1',): 3455, ('HARD2',): 502, ('HARD3',): 376})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.FreqDist(senses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the sense 'HARD1' is occurring vastly more often than the other two senses. Also, the `FreqDist` function has not counted any instances where the sense was not clear (multiple senses present in a single sentence), which means that all of the input instances can be used.  \n",
    "The **baseline classification accuracy** of the classifier is the share of the of the most wide-spread class in the data (in this case \"HARD1\"): 3455/4333 = **79.74%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Split the data into training and holdout (test) set  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training, dev-test, and holdout sets\n",
    "\n",
    "seed(42) # Inintialize random seed\n",
    "\n",
    "size = int(len(instances) * 0.1)\n",
    "train_set, holdout_set = instances[size:], instances[:size]\n",
    "\n",
    "def split_train_test(x, n_test):\n",
    "    \"\"\"Randomly splits a list into two lists with n_test records in one, \n",
    "    and the remainder in the other one.\"\"\"\n",
    "    \n",
    "    random.shuffle(x)\n",
    "    \n",
    "    return x[:n_test],x[n_test:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extract the word context and part of speech features  \n",
    "In this part, I set up functions to extract words and part of speech (POS) tags around the target word from each instance. Then, the most frequent items from word and POS context per sense will be used as classifier features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the set of stopwords\n",
    "stop_words = list(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(l, ltypes=(list, tuple)):\n",
    "    \"\"\"Source: http://rightfootin.blogspot.de/2006/09/more-on-python-flatten.html\"\"\"\n",
    "    ltype = type(l)\n",
    "    l = list(l)\n",
    "    i = 0\n",
    "    while i < len(l):\n",
    "        while isinstance(l[i], ltypes):\n",
    "            if not l[i]:\n",
    "                l.pop(i)\n",
    "                i -= 1\n",
    "                break\n",
    "            else:\n",
    "                l[i:i + 1] = l[i]\n",
    "        i += 1\n",
    "    return ltype(l)\n",
    "\n",
    "def extract_before_after_features(instance,k_before=4,k_after=4,remove_punct=True,stop_words=None, \n",
    "                                  min_word_length = None, return_lists = True):\n",
    "    \"\"\"Parses a SensevalInstance and returns a dictionary with k words and POS tags \n",
    "    before and k words and POS tags after the target word at position i applying the \n",
    "    filters: remove punctuation, remove stop words from a provided list, remove all \n",
    "    short words with a length under min_word_length\"\"\"\n",
    "    \n",
    "    i=instance.position\n",
    "    puncts = [item for item in string.punctuation] + [item*2 for item in string.punctuation]\n",
    "\n",
    "    # Extract before and after parts\n",
    "\n",
    "    sent_words = [item[0] for item in instance.context]\n",
    "    sent_pos = [item[1] for item in instance.context]\n",
    "    before = zip(sent_words[:i],sent_pos[:i])\n",
    "    after = zip(sent_words[i+1:],sent_pos[i+1:])\n",
    "\n",
    "    # Apply cleaning\n",
    "\n",
    "    if stop_words is not None:\n",
    "        before = [(word,pos) for (word,pos) in before if word not in stop_words]\n",
    "        after = [(word,pos) for (word,pos) in after if word not in stop_words]\n",
    "    if remove_punct is True:\n",
    "        before = [(word,pos) for (word,pos) in before if word not in puncts]\n",
    "        after = [(word,pos) for (word,pos) in after if word not in puncts]\n",
    "    if min_word_length is not None:\n",
    "        before = [(word,pos) for (word,pos) in before if len(word) > min_word_length]\n",
    "        after = [(word,pos) for (word,pos) in after if len(word) > min_word_length]\n",
    "        \n",
    "    output = dict(\n",
    "    words_before = [word for (word,pos) in before[-k_before:]],\n",
    "    pos_before = [pos for (word,pos) in before[-k_before:]],\n",
    "    words_after = [word for (word,pos) in after[:k_after]],\n",
    "    pos_after = [pos for (word,pos) in after[:k_after]]\n",
    "    )\n",
    "    \n",
    "#   Make sure that start/end of the sentence are tagged as empty \n",
    "    for k, v in output.iteritems():\n",
    "        if len(v) == 0:\n",
    "            output[k] = ['EMPTY']\n",
    "\n",
    "    if return_lists == True:\n",
    "        return output\n",
    "    \n",
    "    else:\n",
    "        feature_dict = dict()\n",
    "\n",
    "        for key in output.keys():\n",
    "            for idx, item in enumerate(output[key]):\n",
    "                feature_dict[key+'_'+str(idx)] = item\n",
    "        \n",
    "        return feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SensevalInstance(word=u'hard-a', position=19, context=[('david', 'NNP'), ('ogden', 'NNP'), ('stiers', 'NNP'), ('makes', 'VBZ'), ('a', 'DT'), ('valiant', 'JJ'), ('effort', 'NN'), ('to', 'TO'), ('bring', 'VB'), ('the', 'DT'), ('town', 'NN'), (\"'s\", 'POS'), ('mayor', 'NN'), ('to', 'TO'), ('life', 'NN'), (',', ','), ('but', 'CC'), ('often', 'RB'), ('is', 'VBZ'), ('hard', 'JJ'), ('to', 'TO'), ('decipher', 'VB'), ('because', 'IN'), ('of', 'IN'), ('an', 'DT'), ('aggressive', 'JJ'), ('southern', 'NNP'), ('accent', 'NN'), ('and', 'CC'), ('blustery', 'JJ'), ('tone', 'NN'), ('.', '.')], senses=('HARD1',))\n"
     ]
    }
   ],
   "source": [
    "instance = train_set[0]\n",
    "print instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos_after': ['VB', 'JJ', 'NNP', 'NN', 'JJ'],\n",
       " 'pos_before': ['NN', 'POS', 'NN', 'NN', 'RB'],\n",
       " 'words_after': ['decipher', 'aggressive', 'southern', 'accent', 'blustery'],\n",
       " 'words_before': ['town', \"'s\", 'mayor', 'life', 'often']}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_before_after_features(instance,k_before=5,k_after=5,remove_punct=True,\n",
    "                              stop_words=stop_words,min_word_length=None,return_lists = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can inspect the most frequent contexts per sense to understand the differences between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sense: HARD1\n",
      "\n",
      "Most common words before:,\n",
      "[('EMPTY', 714), ('would', 119), ('said', 112), ('make', 92), ('even', 65), ('much', 63), ('may', 59), ('going', 59), ('find', 59), ('makes', 47), ('people', 46), ('really', 46), ('one', 44), ('made', 36), ('like', 36)] \n",
      "\n",
      "Most common words after:,\n",
      "[('said', 238), ('time', 232), ('get', 144), ('believe', 130), ('find', 117), ('imagine', 92), ('EMPTY', 84), ('say', 83), ('see', 78), ('people', 68), ('way', 62), ('tell', 59), ('part', 58), ('one', 57), ('come', 57)] \n",
      "\n",
      "Sense: HARD2\n",
      "\n",
      "Most common words before:,\n",
      "[('take', 48), ('EMPTY', 44), ('said', 24), ('long', 17), ('taking', 15), ('years', 12), ('little', 12), ('get', 11), ('one', 10), ('good', 9), ('people', 9), (\"'re\", 9), ('took', 8), ('lot', 8), ('also', 8)] \n",
      "\n",
      "Most common words after:,\n",
      "[('work', 156), ('look', 81), ('feelings', 32), ('said', 22), ('line', 17), ('time', 14), ('EMPTY', 11), ('way', 10), ('day', 8), ('people', 8), ('business', 7), ('freedom', 7), ('fast', 7), ('evidence', 7), ('says', 6)] \n",
      "\n",
      "Sense: HARD3\n",
      "\n",
      "Most common words before:,\n",
      "[('rock', 27), ('EMPTY', 13), ('pkd', 10), ('made', 10), ('one', 8), ('said', 8), ('time', 8), ('caught', 7), ('ground', 7), ('firm', 7), ('good', 6), ('first', 6), ('like', 6), ('may', 5), ('including', 5)] \n",
      "\n",
      "Most common words after:,\n",
      "[('place', 22), ('cover', 17), ('surface', 15), ('EMPTY', 14), ('red', 12), ('soft', 12), ('plastic', 11), ('wheat', 9), ('material', 8), ('packed', 8), ('surfaces', 8), ('cheese', 7), ('shell', 7), ('edge', 7), ('spring', 7)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "senses = ['HARD1','HARD2','HARD3']\n",
    "\n",
    "for sense in senses:\n",
    "    sense_instances = [item for item in train_set if item.senses[0] == sense]\n",
    "\n",
    "    before = []\n",
    "    after = []\n",
    "    for instance in sense_instances:\n",
    "        features = extract_before_after_features(instance,k_before=5,k_after=5,\n",
    "                                                 remove_punct=True,stop_words=stop_words,min_word_length=2,return_lists = True)\n",
    "        before.append(features['words_before'])\n",
    "        after.append(features['words_after'])\n",
    "    \n",
    "    before = flatten(before)\n",
    "    after = flatten(after)\n",
    "    print 'Sense: '+sense+'\\n'\n",
    "    print 'Most common words before:,\\n',nltk.FreqDist(before).most_common(15),'\\n'\n",
    "    print 'Most common words after:,\\n',nltk.FreqDist(after).most_common(15),'\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the distributions above that `HARD3` obviously stands for a physical property of withstanding pressure, but the difference between `HARD1` and `HARD2` is more subtle. It seems as if the first sense is more related to \"difficulty\" (hard time, hard to get, hard to believe), whereas the second is more about \"a lack of kindness\" (hard look, hard feelings, hard line)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to prepare the features, we will extract the 300 most common features appearing before and after the target word and construct a feature extractor function that records their occurrences in a given instance context. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Build a Naive Bayes classifier and test it on the dev-test set\n",
    "In this part, the most frequent word and POS features per sense will be used to train a Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3120 780\n"
     ]
    }
   ],
   "source": [
    "# Split into training and test\n",
    "size = int(len(train_set) * 0.2)\n",
    "training, dev_test = train_set[size:], train_set[:size]\n",
    "print len(training), len(dev_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('HARD1',): 2242, ('HARD2',): 502, ('HARD3',): 376})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check label distributions in the training and dev_test\n",
    "nltk.FreqDist([item.senses for item in training])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('HARD1',): 780})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.FreqDist([item.senses for item in dev_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, a simple random sampling returns an extremely biased dev-test set with just one class. In order to avoid this, we shall take 1/2 of all senses with lower counts and an equal amount of the instances with the widespread sense for the training and save the rest for dev-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sense1_train_set = [item for item in train_set if item.senses[0]=='HARD1']\n",
    "sense2_train_set = [item for item in train_set if item.senses[0]=='HARD2']\n",
    "sense3_train_set = [item for item in train_set if item.senses[0]=='HARD3']\n",
    "\n",
    "samp_size_3 = int(len(sense3_train_set) * 0.5)\n",
    "training_3, dev_test_3 = sense3_train_set[samp_size_3:], sense3_train_set[:samp_size_3]\n",
    "\n",
    "samp_size_2 = int(len(sense2_train_set) * 0.5)\n",
    "training_2, dev_test_2 = sense2_train_set[samp_size_2:], sense2_train_set[:samp_size_2]\n",
    "\n",
    "# Note the samp_size_2 used below\n",
    "training_1, dev_test_1 = sense1_train_set[samp_size_2:], sense1_train_set[:samp_size_2]\n",
    "\n",
    "training = flatten([training_1,training_2,training_3])\n",
    "dev_test = flatten([dev_test_1,dev_test_2,dev_test_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('HARD1',): 251, ('HARD2',): 251, ('HARD3',): 188})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.FreqDist([item.senses for item in dev_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a more balanced dev_test and training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up feature extraction\n",
    "\n",
    "def featurizer_0(instance):\n",
    "    return (extract_before_after_features(instance,k_before=3,k_after=3,\n",
    "                                                     remove_punct=True,stop_words=None,min_word_length=2,\n",
    "                                                     return_lists = False) )\n",
    "\n",
    "def labeler(instance):\n",
    "    return instance.senses[0]\n",
    "\n",
    "training_ft_0 = [ (featurizer_0(instance), labeler(instance)) for instance in training]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'pos_after_0': 'NN',\n",
       "  'pos_after_1': 'DT',\n",
       "  'pos_after_2': 'NN',\n",
       "  'pos_before_0': 'DT',\n",
       "  'words_after_0': 'thing',\n",
       "  'words_after_1': 'the',\n",
       "  'words_after_2': 'world',\n",
       "  'words_before_0': 'the'},\n",
       " 'HARD1')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_ft_0[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_0 = nltk.NaiveBayesClassifier.train(training_ft_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "           words_after_0 = 'look'          HARD2 : HARD1  =     68.9 : 1.0\n",
      "          words_before_0 = 'EMPTY'         HARD1 : HARD3  =     58.8 : 1.0\n",
      "           words_after_0 = 'work'          HARD2 : HARD3  =     48.9 : 1.0\n",
      "          words_before_1 = 'rock'          HARD3 : HARD1  =     41.7 : 1.0\n",
      "           words_after_0 = 'for'           HARD1 : HARD2  =     31.3 : 1.0\n",
      "             pos_after_0 = 'VB'            HARD1 : HARD3  =     31.0 : 1.0\n",
      "           words_after_0 = 'cover'         HARD3 : HARD1  =     30.0 : 1.0\n",
      "             pos_after_0 = 'VBN'           HARD3 : HARD1  =     29.2 : 1.0\n",
      "          words_before_1 = 'take'          HARD2 : HARD1  =     24.1 : 1.0\n",
      "          words_before_1 = None            HARD1 : HARD3  =     19.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier_0.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most informative features show some of the sense distinctions discussed above: combination \"[HARD] look\" points to the second meaning (lack of compassion), and \"rock [HARD]\" is predictive of the third meaning (physical property)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(dev_test, featurizer, classifier):\n",
    "    \"\"\"\n",
    "    Returns the accuracy, a contingency table, and the most informative features\n",
    "    of an NLTK classifier.\n",
    "    Based on the code from: Natural Language Processing with Python\n",
    "    by Steven Bird, Ewan Klein, and Edward Loper. 2009, O'Reilly Media\n",
    "    \"\"\"\n",
    "    # Generate test features\n",
    "    dev_test_ft = [ (featurizer(instance), labeler(instance)) for instance in dev_test]\n",
    "\n",
    "    # Score the model on the test features\n",
    "    model_out = [classifier.classify(item[0]) for item in dev_test_ft]\n",
    "\n",
    "    # Evaluate the accuracy\n",
    "    accr = nltk.classify.accuracy(classifier, dev_test_ft)\n",
    "    \n",
    "\n",
    "    # Confusion matrix\n",
    "    true_label = [item[1] for item in dev_test_ft]\n",
    "    \n",
    "    \n",
    "    # Errors: Compare the true label with the classifier output\n",
    "    errors = []\n",
    "    for item in zip(dev_test_ft,model_out):\n",
    "        if item[0][1] != item[1]:\n",
    "            errors.append( (item[0][1], item[1], item[0][0]))\n",
    "    \n",
    "    return dict(model_out = model_out,true_label=true_label,accr=accr,errors=errors)\n",
    "\n",
    "def print_eval_results(classifier, eval_output,err_cnt):\n",
    "    \"Prints model evaluation output\"\n",
    "    \n",
    "    \n",
    "    print (\"Accuracy on the test set: {}% \\n\".format(eval_output[\"accr\"]*100))\n",
    "    # Main features \n",
    "    classifier.show_most_informative_features(10)\n",
    "    \n",
    "    print \"\\n Confusion Matrix: \\n\"\n",
    "    print nltk.ConfusionMatrix(eval_output[\"true_label\"],eval_output[\"model_out\"])\n",
    "    print \"\\n Errors: \\n\", \n",
    "    for (tag, guess, name) in eval_output[\"errors\"][:err_cnt]: \n",
    "        print 'correct=%-8s guess=%-8s name=%-30s' %(tag, guess, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 76.8115942029% \n",
      "\n",
      "Most Informative Features\n",
      "           words_after_0 = 'look'          HARD2 : HARD1  =     68.9 : 1.0\n",
      "          words_before_0 = 'EMPTY'         HARD1 : HARD3  =     58.8 : 1.0\n",
      "           words_after_0 = 'work'          HARD2 : HARD3  =     48.9 : 1.0\n",
      "          words_before_1 = 'rock'          HARD3 : HARD1  =     41.7 : 1.0\n",
      "           words_after_0 = 'for'           HARD1 : HARD2  =     31.3 : 1.0\n",
      "             pos_after_0 = 'VB'            HARD1 : HARD3  =     31.0 : 1.0\n",
      "           words_after_0 = 'cover'         HARD3 : HARD1  =     30.0 : 1.0\n",
      "             pos_after_0 = 'VBN'           HARD3 : HARD1  =     29.2 : 1.0\n",
      "          words_before_1 = 'take'          HARD2 : HARD1  =     24.1 : 1.0\n",
      "          words_before_1 = None            HARD1 : HARD3  =     19.4 : 1.0\n",
      "\n",
      " Confusion Matrix: \n",
      "\n",
      "      |   H   H   H |\n",
      "      |   A   A   A |\n",
      "      |   R   R   R |\n",
      "      |   D   D   D |\n",
      "      |   1   2   3 |\n",
      "------+-------------+\n",
      "HARD1 |<225> 13  13 |\n",
      "HARD2 |  30<192> 29 |\n",
      "HARD3 |  23  52<113>|\n",
      "------+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "\n",
      " Errors: \n",
      "correct=HARD1    guess=HARD3    name={'pos_after_0': 'EMPTY', 'pos_before_1': 'NNS', 'pos_before_0': 'PRP$', 'pos_before_2': 'CC', 'words_after_0': 'EMPTY', 'words_before_0': 'our', 'words_before_1': 'children', 'words_before_2': 'but'}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the features and classifier\n",
    "eval_0 = evaluate_model(dev_test=dev_test, featurizer=featurizer_0,classifier=classifier_0)\n",
    "print_eval_results(classifier_0,eval_0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier using words and POS tags performs significantly better than a random assignment to one of the three classes (in the training set they are almost balanced, so the baseline accuracy would be below 40%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test the classifier on the holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 88.4526558891% \n",
      "\n",
      "Most Informative Features\n",
      "             pos_after_0 = 'VB'            HARD1 : HARD2  =    185.7 : 1.0\n",
      "           words_after_0 = 'work'          HARD2 : HARD3  =     88.7 : 1.0\n",
      "           words_after_0 = 'look'          HARD2 : HARD1  =     79.9 : 1.0\n",
      "           words_after_0 = 'for'           HARD1 : HARD2  =     48.1 : 1.0\n",
      "          words_before_1 = 'rock'          HARD3 : HARD1  =     46.8 : 1.0\n",
      "          words_before_2 = 'long'          HARD2 : HARD1  =     44.9 : 1.0\n",
      "          words_before_1 = 'take'          HARD2 : HARD1  =     35.3 : 1.0\n",
      "          words_before_0 = 'EMPTY'         HARD1 : HARD3  =     34.3 : 1.0\n",
      "           words_after_0 = 'cover'         HARD3 : HARD1  =     29.5 : 1.0\n",
      "             pos_after_0 = 'VBN'           HARD3 : HARD1  =     28.6 : 1.0\n",
      "\n",
      " Confusion Matrix: \n",
      "\n",
      "      |   H   H   H |\n",
      "      |   A   A   A |\n",
      "      |   R   R   R |\n",
      "      |   D   D   D |\n",
      "      |   1   2   3 |\n",
      "------+-------------+\n",
      "HARD1 |<383> 27  23 |\n",
      "HARD2 |   .  <.>  . |\n",
      "HARD3 |   .   .  <.>|\n",
      "------+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "\n",
      " Errors: \n"
     ]
    }
   ],
   "source": [
    "# Train NB classifier on all training data\n",
    "\n",
    "train_ft_final = [ (featurizer_0(instance), labeler(instance)) for instance in train_set]\n",
    "classifier_final = nltk.NaiveBayesClassifier.train(train_ft_final)\n",
    "\n",
    "# Evaluate the features and the trained classifier\n",
    "eval_test = evaluate_model(dev_test=holdout_set, featurizer=featurizer_0,classifier=classifier_final)\n",
    "print_eval_results(classifier_final,eval_test,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier achieves a higher accuracy on the holdout set because it only contains the instances of the most dominant sense in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference \n",
    "1) [Chapter 6: Learning to Classify Text](http://www.nltk.org/book/ch06.html) from Natural Language Processing with Python, by Steven Bird, Ewan Klein and Edward Loper, Copyright © 2014 the authors   \n",
    "2) University of Edinburgh [FNLP 2017: Lab Session 5: Word Sense Disambiguation](https://www.inf.ed.ac.uk/teaching/courses/fnlp/Tutorials/7_WSD/tutorial.html)\n",
    "Henry S. Thompson, based on original by Alex Lascarides, 2017  \n",
    "3) https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python  \n",
    "4) https://docs.python.org/2/library/stdtypes.html#dict.iteritems"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
