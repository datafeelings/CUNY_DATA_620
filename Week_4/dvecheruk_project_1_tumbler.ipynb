{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUNY MSDA Fall 2017 Semester\n",
    "### DATA 620 \n",
    "### Week 4 Homework Assigment \n",
    "By Dmitriy Vecheruk\n",
    "\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assignment**\n",
    "  \n",
    "Your task in this week’s assignment is to identify an interesting set of network data that is available on the web (either through web scraping or web APIs) that could be used for analyzing and comparing centrality measures across nodes.  As an additional constraint, there should be at least one categorical variable available for each node (such as “Male” or “Female”; “Republican”, “Democrat,” or “Undecided”, etc.)  \n",
    "  \n",
    "In addition to identifying your data source, you should create a high level plan that describes how you would load the data for analysis, and describe a hypothetical outcome that could be predicted from comparing degree centrality across categorical groups. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "  \n",
    "**Solution**\n",
    "  \n",
    "  \n",
    "*1) Data source*:  \n",
    "I would like to use a popular image/media blogging platform Tumblr to investigate the relationships between a sample of blogs. Tumblr allows a user to \"like\" other users' individual posts, and also to \"follow\" their blogs to get continuous updates on their activity.   \n",
    "My analysis will test the hypothesis that blogs of users that have given a lot of \"likes\" to others will also have a higher degree centrality, as other users will \"follow\" these blogs in return for the \"likes\". \n",
    "   \n",
    "*2) Data collection approach*:  \n",
    "First, I will use the [`pytumblr`](https://github.com/tumblr/pytumblr) module developed by Tumblr as an API wrapper for the Python language. Using this module, I will collect the data on the followers' of a seed blog, and recursively their followers as well.\n",
    "  \n",
    "Secondly, I will use the API to collect the number of likes per blog in the dataset and convert it into a binary categorical variable of having given below / above a certain number n of likes to others.\n",
    "  \n",
    "*3) Data analysis approach*:  \n",
    "I will use [`networkx`](https://networkx.github.io/documentation/networkx-1.10/reference/algorithms.html) to build the graph of the network and compute degree centrality for each blog. I would then apply a two-means t-test to test the average degree centrality for the blogs that have given more and less likes. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
